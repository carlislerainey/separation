% Generated by roxygen2 (4.0.2): do not edit by hand
\name{sim_post_gelman}
\alias{sim_post_gelman}
\title{Obtain posterior simulations using Gelman et al.'s suggested Cauchy prior.}
\usage{
sim_post_gelman(formula, data, n_sims = 1000, n_burnin = n_sims/2,
  n_thin = 1, n_chains = 3, n_cores = n_chains, tune = 1,
  scale_int = 10, scale_coef = 2.5)
}
\arguments{
\item{formula}{A logistic regression model. Importantly, the explanatory variables should
be rescaled so that continuous variables have mean zero and standard deviation one-half
and binary variable are centered at zero. This can be done automatically with the \code{rescale()} function
in the \code{arm} package. See Gelman (2008) and Gelman et al (2008).}

\item{data}{A data frame.}

\item{n_sims}{The number of simulations after the burn-in period.}

\item{n_burnin}{The number of burn-in iterations for the sample.}

\item{n_thin}{The thinning interval used in the simulation. The number of MCMC
iterations must be divisible by this value.}

\item{n_chains}{The number of MCMC chains being run.}

\item{n_cores}{The number of MCMC cores. Defaults to the number of chains.}

\item{tune}{The tuning parameter for the Metropolis sampling. Can be either a
positive scalar or a (k+1)-vector, where k is the number of variables in the
model. Presently passed to \code{MCMCmetrop1R}.}

\item{scale_int}{The scale paramater for the Cauchy prior on the intercept. As
suggested by Gelman et al. (2008), this defaults to 10.}

\item{scale_int}{The scale paramater for the Cauchy prior on the coefficients. As
suggested by Gelman et al. (2008), this defaults to 2.5.}
}
\description{
\code{sim_post_gelman()} uses a Metropolis algorithm to obtain posterior
simulations using Gelman et al.'s suggested default prior.
}
\references{
Gelman, Andrew. 2008. "Scaling Regression Inputs by Dividing by
  Two Standard Deviations." Statistics in Medicine 27(15):2865–2873.

Gelman, Andrew, Aleks Jakulin, Maria Grazia Pittau, and Yu-Sung
  Su. 2008. "A Weakly Informative Prior Distribution for Logistic and Other
  Regression Models." The Annals of Applied Statistics 2(4):1360–1383.
}

